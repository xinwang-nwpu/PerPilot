# PerPilot

## üìã Project Overview

Large multi-model (LMM)-based mobile agents show great potential for assisting users in performing instruction-driven tasks. However, these agents typically struggle with **personalized instructions**‚Äîthose containing ambiguous, user-specific context‚Äîa challenge that has been largely overlooked in previous research.

This repository presents **PerPilot**, an innovative framework designed to address the critical gap in personalized instruction handling for next-generation mobile agents.

## üîç Core Challenge

Modern mobile agents face significant limitations when processing:

* Ambiguous user requests requiring contextual understanding

* User-specific instructions depends on personal preferences or historical interactions

* Task execution in diverse mobile scenarios with minimal intervention

## üí° Our Solution

We introduce two key innovations to address these challenges:

### 1. PerInstruct Dataset

A novel human-annotated dataset featuring:

* Diverse personalized instructions across various mobile scenarios

* Rich contextual information for training and evaluation

* Comprehensive coverage of real-world user interaction patterns

### 2. PerPilot Framework

A plug-and-play architecture powered by large language models (LLMs) that enables mobile agents to:

* Autonomously perceive personalized elements in user instructions

* Understand context-specific requirements

* Execute complex tasks with minimal user input

## üöÄ Key Features

PerPilot employs two complementary approaches for personalized task completion:

| Approach                        | Description                                                               |
| ------------------------------- | ------------------------------------------------------------------------- |
| **Memory-based Retrieval**      | Leverages historical user data to provide contextually relevant responses |
| **Reasoning-based Exploration** | Uses LLM-powered reasoning to handle novel or ambiguous instructions      |

Fully automatic execution and verification of instructions.

For users, it is easy to expand the instruction benchmark.

## üìä Experimental Results

Our evaluations demonstrate that PerPilot:

* Effectively handles personalized tasks with minimal user intervention

* Progressively improves performance with continued use

* Outperforms existing mobile agents in context-aware task execution

* Establishes the importance of personalization-aware reasoning for next-generation agents

## üì± Get Start
The project provides two operating environments: real mobile phones and mobile simulators.

1.real mobile phones
To run on a real phone, you first need to download the ADB Keyboard and then set the default input method to ADB Keyboard.
https://github.com/senzhk/ADBKeyBoard

After the setup is complete, you need an adb software on your computer, either set it to the system path or specify the adb path in your project.

Then you need to connect your phone to the computer via USB debugging or a wireless connection.

Finally, download the files required by the module and agent to start using it.


2.mobile simulator
This project is implemented based on the MUMU emulator, which is an emulator compatible with Chinese apps.
To reproduce it, you need to download this emulator from the link now.
link is https://mumu.163.com/

You can create a mobile environment in this emulator and install the required software or download the image used in our lab to quickly and accurately reproduce it.

our image link will be launched soon

Then you need to set the command-line tool of the MuMu emulator in the environment variables or system path.The tool position and related function codes can be referenced at the website https://mumu.163.com/help/20240807/40912_1170006.html.

Finally, download the files required by the module and agent to start using it.



## üìù Conclusion

PerPilot represents a significant step forward in creating more intuitive and user-centric mobile agents. By combining memory-based retrieval with advanced reasoning capabilities, our framework paves the way for more natural human-machine interaction in mobile environments.



